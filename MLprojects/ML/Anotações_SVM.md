## ALGORITMO-DE-ML-SVM

O algoritmo **SVM (Support Vector Machine)** √© um m√©todo de **Aprendizado Supervisionado** utilizado tanto para **classifica√ß√£o** quanto para **regress√£o**. Seu objetivo principal √© encontrar uma **fronteira de decis√£o √≥tima** que separe os dados de diferentes classes com a **maior margem poss√≠vel**.

De acordo com **Russell e Norvig (2022)** e **Bishop (2006)**, a SVM busca maximizar a dist√¢ncia entre os pontos mais pr√≥ximos de cada classe ‚Äî chamados de **vetores de suporte** ‚Äî e o hiperplano de separa√ß√£o.

---

### üîπ Conceitos Fundamentais

* **Hiperplano:**  
  Em um espa√ßo bidimensional, √© uma reta; em dimens√µes maiores, trata-se de uma superf√≠cie que separa os dados.

* **Margem M√°xima:**  
  A SVM escolhe o hiperplano que maximiza a dist√¢ncia m√≠nima entre ele e os vetores de suporte.

* **Vetores de Suporte:**  
  S√£o os exemplos de treino mais pr√≥ximos da fronteira de decis√£o. Apenas eles influenciam diretamente o modelo final.

---

### üîπ Classifica√ß√£o Linear

Quando os dados s√£o **linearmente separ√°veis**, a SVM encontra um hiperplano que satisfaz:

- W . x + b = 0 

Onde:
- `w` √© o vetor normal ao hiperplano  
- `b` √© o termo de bias  
- `x` representa os dados de entrada  

A decis√£o da classe √© dada pelo **sinal da fun√ß√£o**:

* valor positivo ‚Üí classe A  
* valor negativo ‚Üí classe B  

---

### üîπ Classifica√ß√£o N√£o Linear e Kernel Trick

Quando os dados **n√£o s√£o linearmente separ√°veis**, a SVM utiliza o **Kernel Trick**, que projeta os dados para um espa√ßo de maior dimens√£o, onde a separa√ß√£o linear se torna poss√≠vel.

Kernels comumente utilizados:
* **Linear**
* **Polinomial**
* **RBF (Gaussian Kernel)**
* **Sigmoid**

Essa t√©cnica evita o c√°lculo expl√≠cito da proje√ß√£o, reduzindo o custo computacional.

---

### üîπ Par√¢metros Importantes

* **C (Regulariza√ß√£o):**  
  Controla o trade-off entre margem m√°xima e erro de classifica√ß√£o.
  - C alto ‚Üí menos erros no treino (risco de overfitting)
  - C baixo ‚Üí maior margem (melhor generaliza√ß√£o)

* **Kernel:**  
  Define o tipo de fronteira de decis√£o utilizada.

* **Gamma (kernels n√£o lineares):**  
  Controla a influ√™ncia de um √∫nico exemplo de treino sobre o modelo.

---

### üîπ Fluxo Geral do Algoritmo

1. **Divis√£o dos Dados:**  
   Normalmente utiliza-se o esquema **70/30** ou **80/20** (treino/teste).

2. **Normaliza√ß√£o:**  
   Etapa fundamental, pois a SVM √© sens√≠vel √† escala dos dados.

3. **Treinamento:**  
   O algoritmo identifica os vetores de suporte e define o hiperplano √≥timo.

4. **Predi√ß√£o:**  
   Novas amostras s√£o classificadas com base na posi√ß√£o relativa ao hiperplano.

5. **Avalia√ß√£o:**  
   M√©tricas comumente utilizadas:
   * Acur√°cia
   * Matriz de confus√£o
   * Erro m√©dio (para regress√£o)

---

### üîπ Observa√ß√µes Importantes

* A SVM apresenta excelente desempenho em **espa√ßos de alta dimens√£o**.
* A escolha adequada do **kernel** e dos **hiperpar√¢metros** √© essencial.
* Pode apresentar custo computacional elevado para grandes bases de dados.
